* 定义

```
二分类，线性分类模型

f(x) = sign(wx+b)

x:输入的特征向量，f(x) ∈ （-1，1）

sign 为符号函数

wx+b=0 ： w 是 权重向量或法向量，x 为特征向量，几何意义上为一个超平面

线性可分数据集：对所有的实例，都能正确划分 ，即 y能正确为 1 ，-1

线性不可分：不能正确划分
```

* wx+b=0

```
1、证明 w 为法向量

  设 超平面上两个点 x0=(t1,t2,...tn)  x1=(p1,p2,...pn)

  w = (w1,w2,w3,w4.....wn)

  向量内积

  wx0+b=w1t1+....+wntn+b=0

  wx1+b=w1p1+....+wnpn+b=0

  两式相减，得到

  w(x1-x0) = w1(p1-t1)+....+wn(pn-tn)=0

  观察到   p1-t1 为超平面上的一条直线向量， 只有法向量 与 平面上的任意直线的 向量内积 =0 

  所以 得到 w 向量 为 法向量

2、b 表示 截距，是一个实数
```

* 点到超平面的距离  

```
（1/||w|| ) * | wx+b | ， x 为点

证明 ：

设 x0 为平面外任一点 x0=(t1,t2,...tn) , x1 为 x0 在 超平面上的投影点 x1=(p1,p2....pn)

则 向量 x0x1 同 法向量 平行 

wx1+b = 0  - > w1p1+w2p2+....+wnpn+b=0

向量公式  a*b=|a||b|cosƟ   a,b 为向量

w*x0x1=|w||x0x1|cosƟ 因为平行，故 Ɵ 为 0 或 180度，故 cosƟ = 1 或 -1

|x0x1| = 点到 平面的距离

w1(p1-t1)+...+wn(pn-tn) = |w||x0x1|cosƟ

w1p1+...+wnpn-(w1t1+....+wntn) = |w||x0x1|cosƟ

-b-(w1t1+....+wntn) = |w||x0x1|cosƟ

两边分别绝对值

|w1t1+....+wntn+b| / ||w||  = |x0x1|

观察到 w1t1+....+wntn+b 即为 wx+b 其中 x 为 x0 点，平面外的一点

||w|| : 法向量 的 模的绝对值
```

* 损失函数

```
-(1/||w||) * y * (wx+b)

损失函数 计算的针对是 误分类点，故 -y(wx+b)  > 0 即 wx+b > 0 ,y 为-1；wx+b < 0 ,y 为 1 

故  -y*(wx+b) = | wx+b | 

为何损失函数 不考虑 1/||w|| ? 

解释 ： 

结果 L= -∑y*(wx+b)  x 为所有误分类点
```

* 目的

```
学习训练集，使训练集能够线性可分--训练集正负样本划分完全对

得到了模型函数 wx+b=0 的 超平面
```

* 学习策略

```
模型必然会有损失函数

经验损失函数 最小即为 学习模型最优
```



